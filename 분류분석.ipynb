{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ysyblog.tistory.com/68?category=1144778\n",
    "\n",
    "https://harryp.tistory.com/871"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/2.png)![](image/3.png)![](image/4.png)![](image/5.png)![](image/6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류분석\n",
    "* 의사결정 나무\n",
    "  * from sklearn.tree import DecisionTreeClassifier\n",
    "* 배깅\n",
    "  * 랜덤 포레스트\n",
    "  * from sklearn.ensemble import RandomForestClassifier\n",
    "* 부스팅\n",
    "* SVM\n",
    "  * from sklearn.svm import SVC, LinearSVC # svc의 c는 classification을 뜻함\n",
    "* KNN\n",
    "  * from sklearn.neighbors import KNeighborsClassifier\n",
    "* 나이브 베이즈\n",
    "  * from sklearn.naive_bayes import GaussianNB\n",
    "* SGD\n",
    "  * from sklearn.linear_model import SGDClassifier\n",
    "* 로지스틱 회귀\n",
    "  * from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 의사결정나무\n",
    "\n",
    "* 용어\n",
    "  * Root Node : 시작 node\n",
    "  * Decision Node (Intermediate Node): 중간 node\n",
    "  * Leaf Node(Terminal Node) : 마지막 단계의 노드로 최종결과를 가진다.\n",
    "* 과대적합(Overfitting) 문제\n",
    "  * 모든 데이터셋이 모두 잘 분류 되어 불순도가 0이 될때 까지 분기해 나간다.\n",
    "  * Root에서 부터 하위 노드가 많이 만들어 질 수록 모델이 복잡해져 과대적합이 발생할 수 있다.\n",
    "  * 과대적합을 막기 위해서는 적당한 시점에 하위노드가 더이상 생성되지 않도록 해야 한다.\n",
    "  * 가지치기(Pruning)라고 한다.\n",
    "  \n",
    "\n",
    "* max_depth: 트리의 최대 깊이(질문수)\n",
    "* max_leaf_nodes: Leaf node 의 최대 개수를 제한\n",
    "* min_samples_leaf: leaf 노드가 되기 위한 sample 수 제한\n",
    "* min_samples_split: 나누는 최소 샘플 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 독립 변수의 조건에 따라 종속 변수를 분리\n",
    "  * 머신러닝의 몇안되는 White box 모델\n",
    "* 결과에 대한 해석이 가능하다.\n",
    "* 과적합(Overfitting)이 잘 일어나는 단점이 있다.\n",
    "* 랜덤 포레스트(Random Forest), Gradient Boosting, Adaptive boosting과 같은 Boosting 계열 앙상블이 결정트리를 기반으로 하고 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     species  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "..       ...  \n",
       "145        2  \n",
       "146        2  \n",
       "147        2  \n",
       "148        2  \n",
       "149        2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['species'] = iris.target\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 문제 정의\n",
    "  * 내가 발견한 Iris 꽃받침(Sepal)의 길이(length)와 폭(width)이 각각 5cm, 3.5cm이고 꽃의 꽃잎(Petal)의 길이와 폭은 각각 1.4cm, 0.25cm이 이었다. 이 꽃는 Iris의 무슨 종일까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(iris.data,#input data(feature)\n",
    "                 iris.target, #output data(label)\n",
    "                 test_size=0.2, #테스트 셋의 비율(전체중 20%, 기본:0.25)\n",
    "                 stratify = iris.target, #각 class들을 같은 비율로 나눈다.\n",
    "                 random_state=1 #random 시드값\n",
    "                )\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "#==> ((120, 4), (30, 4), (120,), (30,))\n",
    "type(X_train), type(y_train)\n",
    "#==> (numpy.ndarray, numpy.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터셋 정확도: 1.0, 테스트데이터셋 정확도:1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# 훈련데이터셋으로 예측\n",
    "pred_train = dt.predict(X_train)\n",
    "# 테스트 데이터셋으로 예측\n",
    "pred_test = dt.predict(X_test)\n",
    "\n",
    "acc_train = accuracy_score(pred_train, y_train)\n",
    "acc_test = accuracy_score(pred_test, y_test)\n",
    "\n",
    "print(f\"훈련데이터셋 정확도: {acc_train}, 테스트데이터셋 정확도:{acc_test}\")\n",
    "#==> 훈련데이터셋 정확도: 1.0, 테스스데이터셋 정확도:0.9666666666666667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40  0  0]\n",
      " [ 0 40  0]\n",
      " [ 0  0 40]]\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm_train = confusion_matrix(y_train, pred_train) #실제값, 예측값\n",
    "cm_test = confusion_matrix(y_test, pred_test)\n",
    "\n",
    "print(cm_train)\n",
    "print(cm_test)\n",
    "\n",
    "# axis=0: 실제, axis=1: 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 의사결정나무 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from graphviz import Source\n",
    "eg = export_graphviz(dt, \n",
    "                     out_file=None, \n",
    "                     feature_names = X.columns,\n",
    "                     class_names = ['White','Red'],\n",
    "                     rounded=True, filled=True)\n",
    "graph = Source(eg)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 피쳐 중요도 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_i = pd.Series(dt.feature_importances_, index=iris_df.columns[:-1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "f_i.sort_values().plot(kind='barh', figsize=(10,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "* 다수의 결정트리를 사용해서 성능을 올린 앙상블 알고리즘의 하나\n",
    "  * 학습데이터를 샘플링해서 다수의 결정트리를 생성하고 이를 기반으로 다수결로 결과를 결정하는 방식\n",
    "  * 다수의 결정트리를 만드는데서 랜덤포레스트라고 부른다.\n",
    "* 처리속도가 빠르며 분류 성능도 높은 모델로 알려져 있다.\n",
    "* 랜덤 포레스트는 텍스트 데이터 같이 매우 차원이 높고 희소한 데이터에는 잘 작동하지 않는다. 이런 데이터에는 선형 모델이 더 적합하다. \n",
    "* 랜덤 포레스트는 선형 모델보다 많은 메모리를 사용하며 훈련과 예측이 느리다. 속도와 메모리 사용에 제약이 있는 애플리케이션이라면 선형 모델이 적합할 수 있다.\n",
    "* 결정 트리의 주요 단점은 훈련 데이터에 과대적합되는 경향이 있다는 것이다. 랜덤 포레스트는 이 문제를 회피할 수 있는 방법이다\n",
    "* 아무런 매개변수 튜닝 없이도 선형 모델이나 단일 결정 트리보다 높은 정확도를 낸다 랜덤 포레스트는 하이퍼 파라미터 조정 없이 기본 설정으로도 좋은 결과를 만들어줄 때가 많다.\n",
    "  \n",
    "* 랜덤포레스트의 절차\n",
    "  * 결정트리의 개수를 하이퍼파라미터로 받는다.\n",
    "  * 랜덤 포레스트를 구성하는 모든 결정트리가 서로 다르도록 만든다.\n",
    "    * 각 트리는 부트스트랩 샘플링(중복을 허용하면서 랜덤하게 샘플링하는 방식)으로 데이터셋을 준비한다. (총데이터의 수는 원래 데이터셋과 동일 하지만 일부는 누락되고 일부는 중복된다.)\n",
    "    * 각 트리는 전체 피처중 일부의 피처만 랜덤하게 가지게 된다.\n",
    "* 각 트리별로 예측결과를 내고 분류의 경우 그 예측을 모아 다수결 투표로 클래스 결과를 낸다.\n",
    "* 회귀의 경우는 예측 결과의 평균을 낸다.\n",
    "\n",
    "* 주요 하이퍼파라미터\n",
    "  * n_estimators\n",
    "    * tree의 개수\n",
    "    * 시간과 메모리가 허용하는 범위에서 클수록 좋다.\n",
    "  * max_features\n",
    "    * 각 트리에서 선택할 feature의 개수\n",
    "    * 클수록 각 트리간의 feature 차이가 없어지고 작을 수록 차이가 많이 나게 된다.\n",
    "  * max_depth, min_samples_leaf, ..\n",
    "    * DecisionTreeClassifier의 하이퍼파라미터들\n",
    "    * 트리의 최대 깊이, 가지를 치기 위한 최소 샘플 수 등 결정 트리에서 과적합을 막기 위한 파라미터들을 랜덤 포레스트에 적용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=3, max_features=5,\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "* K-NN은 이해하기 쉬운 모델이며 튜닝할 하이퍼파라미터의 수가 적어 빠르게 만들 수있다.\n",
    "* 많이 조정하지 않아도 자주 좋은 성능을 발휘한다.\n",
    "* K-NN은 서비스할 모델을 구현할때 보다는 복잡한 알고리즘을 적용해 보기 전에 확인용 또는 base line을 잡기 위한 모델로 사용한다.\n",
    "* 훈련세트가 너무 큰 경우(Feature나 관측치의 개수가 많은 경우) 거리를 계산하는 양이 늘어나 예측이 느려진다.\n",
    "* Feature간의 값의 단위가 다르면 작은 단위의 Feature에 영향을 많이 받게 되므로 전처리로 Scaling작업이 필요하다.\n",
    "* Feature가 너무 많은 경우와 대부분의 값이 0으로 구성된(희소-sparse) 데이터셋에서 성능이 아주 나쁘다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "support vector간의 가장 넓은 margin을 가지는 초평면(결정경계)를 찾는 것이 SVM의 목표\n",
    "\n",
    "* Support Vector: 경계를 찾아내는데 기준이 되는 데이터포인트. 초평면(결정경계)에 가장 가까이 있는 vector(데이터포인트)를 말한다.\n",
    "* margin : 두 support vector간의 너비\n",
    "* margin이 넓은 결정경계를 만드는 함수를 찾는 것.\n",
    "\n",
    "\n",
    "**Hard Margin, Soft Margin**\n",
    "* Overfitting(과적합)을 방지하기 위해 어느정도 오차를 허용하는 방식을 Soft margin이라고 한다. 반대로 오차를 허용하지 않는 방식을 Hard Margin이라고 한다.\n",
    "* 하이퍼파마미터인 C 조정해 마진을 변경한다.\n",
    "* 기본값 1\n",
    "  * 파라미터값을 크게주면 마진폭이 좁아져 마진 오류가 작아지나 Overfitting이 일어날 가능성이 크다.\n",
    "  * 파라미터값을 작게 주면 마진폭이 넓어져 마진 오류가 크다. 훈련데이터에서는 성능이 안좋아지나 일반화(generalization)되어 테스트 데이터의 성능이 올라간다. 그러나 underfitting 이 날 가능성이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "train_test_split(cancer.data, cancer.target, stratify=cancer.target)\n",
    "\n",
    "\n",
    "# Scaling\n",
    "# scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svm = SVC(kernel='linear') #선형 SVM # C_list = [0.01, 0.05, 0.1, 0.5, 1, 10]\n",
    "# svm = LinearSVC()\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "pred_train = svm.predict(X_train_scaled)\n",
    "pred_test = svm.predict(X_test_scaled)\n",
    "\n",
    "pred_test = svm.predict(X_test_scaled)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"train정확도:\", accuracy_score(y_train, pred_train))\n",
    "print('test정확도:', accuracy_score(y_test, pred_test))\n",
    "#train정확도: 0.9929577464788732"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 비선형 데이터 셋에 SVM 적용\n",
    "\n",
    "* 방사기저(radial base function-RBF) 함수\n",
    "  * 커널 서포트 벡터 머신의 기본 커널 함수\n",
    "  * 기준점들이 되는 위치를 지정하고 각 샘플이 그 기준점들과 얼마나 떨어졌는 지를 계산한다. => 유사도(거리)\n",
    "  * 기준점 별 유사도 계산한 값은 원래 값보다 차원이 커지고 선형적으로 구분될 가능성이 커진다.\n",
    "  * rbf(radial basis function) 하이퍼파라미터\n",
    "    * C\n",
    "      * 오차 허용기준. 작은 값일 수록 많이 허용한다.\n",
    "      * 과적합일 경우 값을 감소시키고, 과소적합일 경우 값을 증가 시킨다.\n",
    "    * gamma\n",
    "      * 방사기저함수의 gamma로 규제의 역할을 한다.\n",
    "      * 모델이 과대적합일 경우 값을 감소시키고, 과소적합일 경우 값을 증가시킨다.  \n",
    "      * gamma 방사 기저함수 공식상 감마가 크면 반환값은 작아지고 감마가 작으면 반환값은 커진다. (gamma를 곱하므로)\n",
    "      * 감마가 작을 수록 값들의 거리가 멀어지고(큰값이 결과로 나오므로) 클 수록 거리가 가까워진다. 그래서 gamma 가 크면 거리가 타이트해져 과적합이 일어날 수있다. (공간의 여유가 없므으로)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "rbf_model = SVC(kernel='rbf',  random_state=12, \n",
    "                gamma='auto', probability=True)  #auto: 1/컬럼수, scale: 1/(컬럼수*X분산값)\n",
    "rbf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Reression\n",
    "\n",
    "* 선형회귀 알고리즘을 이용한 이진 분류 모델\n",
    "* Sample이 특정 클래스에 속할 확률을 추정한다.\n",
    "* 로그 손실함수는 최소값을 찾는 정규방적식이 없기 때문에 LogisticRegression은 경사하강법을 이용해 최적화를 진행한다.\n",
    "* 주요 하이퍼 파라미터\n",
    "  * penalty: 과적합을 줄이기 위한 규제방식\n",
    "    * 'l1', 'l2'(기본값), 'elasticnet', 'none'\n",
    "  * C: 규제강도(기본값 1) - 작을 수록 규제가 강하다.\n",
    "  * max_iter(기본값 100) : 경사하강법 반복횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 선형 기반이기 때문에 Scaling 필요\n",
    "\n",
    "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "* 스팸메일에서와 같이 특정 단어가 있다/없다 처럼 이진 속성을 가지고 속성이 아주 많은 경우에는 BernoulliNB 를 주로 적용한다.\n",
    "* 이진 속성이 아닌 일반적인 연속값 속성을 가지는 데이터에는 GaussianNB 를 적용한다.\n",
    "* 스팸메일과 같은 경우에도, 나이브베이즈는 로지스틱회귀 보다 일반적으로 성능이 떨어지므로 잘 사용되지 않는 경향이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "\n",
    "**Boosting**\n",
    "* 부스팅(Boosting)이란 단순하고 약한 학습기(Weak Learner)들를 결합해서 보다 정확하고 강력한 학습기(Strong Learner)를 만드는 방식.\n",
    "* 정확도가 낮은 하나의 모델을 만들어 학습 시킨뒤, 그 모델의 예측 오류는 두 번째 모델이 보완한다. 이 두 모델을 합치면 처음보다는 정확한 모델이 만들어 진다. 합쳐진 모델의 예측 오류는 다음 모델에서 보완하여 계속 더하는 과정을 반복한다.\n",
    "* 약한 학습기들은 앞 학습기가 만든 오류를 줄이는 방향으로 학습한다.\n",
    "\n",
    "**Gradient Boosting**\n",
    "* 처음 모델은 y를 예측 두번째 부터는 앞 모델이 만든 오류를 예측하고 그것을 앞 모델에 업데이트하면 오류를 줄일 수 있다.\n",
    "* 그 오류를 update할 때 뺄까 더할까를 gradient descent 방법을 쓴다. 미분해서 나오는 값의 음수를 취해서 적용.\n",
    "* 학습률을 작게하면 update가 조금씩 크면 많이 하게 된다. 그래서 크게하면 학습데이터에 너무 맞아 과대적합 될 수 있다.\n",
    "* 개별 모델로 Decision Tree 를 사용한다.\n",
    "* depth가 깊지 않은 트리를 많이 연결해서 이전 트리의 오차를 보정해 나가는 방식으로 실행한다.\n",
    "* 오차를 보정할 때 경사하강법(Gradient descent)을 사용한다.\n",
    "* 얕은 트리를 많이 연결하여 각각의 트리가 데이터의 일부에 대해 예측을 잘 수행하도록 하고 그런 트리들이 모여 전체 성능을 높이는 것이 기본 아이디어.\n",
    "* 분류와 회귀 둘다 지원하는 모델 (GradientBoostingClassifier, GrandientBoostingRegressor)\n",
    "* 훈련시간이 많이 걸리고, 트리기반 모델의 특성상 희소한 고차원 데이터에서는 성능이 않좋은 단점이 있다.\n",
    "\n",
    "**주요 파라미터**\n",
    "\n",
    "* Decision Tree 의 가지치기 관련 매개변수\n",
    "  * 각각의 tree가 복잡한 모델이 되지 않도록 한다.\n",
    "* learning rate\n",
    "  * 이전 tree의 오차를 얼마나 강하게 보정할 것인지 제어하는 값.\n",
    "  * 값이 크면 보정을 강하게 하여 복잡한 모델을 만든다. 학습데이터의 정확도는 올라가지만 과대적합이 날 수있다.\n",
    "  * 값을 작게 잡으면 보정을 약하게 하여 모델의 복잡도를 줄인다. 과대적합을 줄일 수 있지만 성능 자체가 낮아질 수있다.\n",
    "  * 기본값 : 0.1\n",
    "* n_estimators\n",
    "  * tree의 개수 지정. 많을 수록 복잡한 모델이 된다.\n",
    "* n_iter_no_change, validation_fraction\n",
    "  * validation_fraction에 지정한 비율만큼 n_iter_no_change에 지정한 반복 횟수동안 검증점수가 좋아 지지 않으면 훈련을 조기 종료한다.\n",
    "* 보통 max_depth를 낮춰 개별 트리의 복잡도를 낮춘다. (5가 넘지 않게) 그리고 n_estimators를 가용시간, 메모리 한도에 맞춘뒤 적절한 learning_rate을 찾는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(learning_rate=0.01)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "#==> GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
    "                        #    learning_rate=0.01, loss='deviance', max_depth=3,\n",
    "                        #    max_features=None, max_leaf_nodes=None,\n",
    "                        #    min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                        #    min_samples_leaf=1, min_samples_split=2,\n",
    "                        #    min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                        #    n_iter_no_change=None, presort='deprecated',\n",
    "                        #    random_state=None, subsample=1.0, tol=0.0001,\n",
    "                        #    validation_fraction=0.1, verbose=0,\n",
    "                        #    warm_start=False)\n",
    "\n",
    "pred_train = gb_clf.predict(X_train)\n",
    "pred_test = gb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost\n",
    "\n",
    "* Gradient Boost 알고리즘을 기반으로 개선해서 나온 모델.\n",
    "* 캐글 경진대회에서 상위에 입상한 데이터 과학자들이 사용한 것을 알려저 유명해짐.\n",
    "* Gradient Boost의 단점인 느린수행시간을 해결하고 과적합을 제어할 수 있는 규제를 제공하여 성능을 높임.\n",
    "\n",
    "* 주요 매개변수\n",
    "  * learning_rate : 학습률, 보통 0.01 ~ 0.2 사이의 값 사용\n",
    "  * n_estimators : week tree 개수\n",
    "  * max_depth: 트리의 depth 지정.\n",
    "  * min_child_weight : 값이 높아지면 under-fitting 됨, CV를 통해 튜닝되어야 한다.\n",
    "  * booster='gbtree' : 트리,회귀(gblinear) 트리가 기본값, 좋은 성능을 내기 때문에 수정할 필요없음\n",
    "  * silent=True : 모델이 적합되는 과정을 이해하기위해선 False으로한다\n",
    "  * colsample_bytree=0.8 : 트리를 생성할때 훈련 데이터에서 변수를 샘플링해주는 비율. 보통0.6~0.9\n",
    "  * colsample_bylevel=0.9 : 트리의 레벨별로 훈련 데이터의 변수를 샘플링해주는 비율. 보통0.6~0.9\n",
    "  * gamma =0 : 노드가 split 되기 위한 loss function의 값이 감소하는 최소값을 정의한다. gamma 값이 높아질 수록 알고리즘은 보수적으로 변하고, loss function의 정의 에 따라 적정값이 달라지기때문에 반드시 튜닝해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators=200,\n",
    "                        learning_rate=0.2,\n",
    "                        max_depth=1)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "# XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "#               colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
    "#               importance_type='gain', interaction_constraints='',\n",
    "#               learning_rate=0.2, max_delta_step=0, max_depth=1,\n",
    "#               min_child_weight=1, missing=nan, monotone_constraints='()',\n",
    "#               n_estimators=200, n_jobs=0, num_parallel_tree=1,\n",
    "#               objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "#               reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
    "#               tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "pred_train = xgb_clf.predict(X_train)\n",
    "pred_test = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM\n",
    "\n",
    "https://greatjoy.tistory.com/72\n",
    "\n",
    "https://greeksharifa.github.io/machine_learning/2019/12/09/Light-GBM/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Light GBM은 트리 기반의 학습 알고리즘인 gradient boosting 방식의 프레임 워크이다.\n",
    "* Light GBM은 나무를 수직으로 확장한다. 반면 다른 알고리즘은 나무를 수평으로 확장한다. \n",
    "* 따라서 기존의 알고리즘은 수평으로 확장하여 포화 트리를 만드는 방향으로 학습하는 반면 leaf-wise tree growth인 LGBM은 최대 delta loss가 증가하도록 잎의 개수를 정한다. \n",
    "* leaf-wise알고리즘은 다른 level-wise 알고리즘보다 낮은 loss를 달성하는 경향이 있다. 데이터의 크기가 작은 경우 leaf-wise는 과적합(overfitting)되기 쉬우므로 max_depth를 줄여줘야 한다.\n",
    "\n",
    "**주요 파라미터**\n",
    "\n",
    "1. learning_rate\n",
    "\n",
    "   * 일반적으로 0.01 ~ 0.1 정도로 맞추고 다른 파라미터를 튜닝한다. 나중에 성능을 더 높일 때 learning rate를 더 줄인다.\n",
    "\n",
    "2. num_iterations\n",
    "\n",
    "   * 기본값이 100인데 1000정도는 해주는게 좋다. 너무 크게하면 과적합이 발생할 수 있다.\n",
    "\n",
    "   * 같은 뜻으로 사용되는 옵션: num_iteration, n_iter, num_tree, num_trees, num_round, num_rounds, num_boost_round, n_estimators\n",
    "\n",
    "3. max_depth\n",
    "\n",
    "   * -1로 설정하면 제한없이 분기한다. feature가 많다면 크게 설정한다. 파라미터 설정 시 우선적으로 설정한다.\n",
    "\n",
    "4. boosting \n",
    "\n",
    "   * 부스팅 방법: 기본값은 gbdt이며 정확도가 중요할때는 딥러닝의 드랍아웃과 같은 dart를 사용한다. 샘플링을 이용하는 goss도 있다.\n",
    "\n",
    "5. bagging_fraction\n",
    "\n",
    "   * 배깅을 하기위해서 데이터를 랜덤 샘플링하여 학습에 사용한다. 비율은 0 < fraction <= 1 이며 0이 되지 않게 해야한다.\n",
    "\n",
    "6. feature_fraction\n",
    "\n",
    "   * feature_fraction이 1보다 작다면 LGBM은 매 iteration(tree)마다 다른 feature를 랜덤하게 추출하여 학습하게된다. 만약, 0.8로 값을 설정하면 매 tree를 구성할 때, feature의 80%만 랜덤하게 선택한다. 과적합을 방지하기 위해 사용할 수 있으며 학습 속도가 향상된다.\n",
    "\n",
    "7. scale_pos_weight\n",
    "\n",
    "   * 클래스 불균형의 데이터 셋에서 weight를 주는 방식으로 positive를 증가시킨다. 기본값은 1이며 불균형의 정도에 따라 조절한다.\n",
    "\n",
    "8. early_stopping_round\n",
    "\n",
    "   * Validation 셋에서 평가지표가 더 이상 향상되지 않으면 학습을 정지한다. 평가지표의 향상이 n round 이상 지속되면 학습을 정지한다.\n",
    "\n",
    "9. lambda_l1, lambda_l2\n",
    "\n",
    "   * 정규화를 통해 과적합을 방지할 수 있지만, 정확도를 저하시킬수도 있기 때문에 일반적으로 default 값인 0으로 둔다.\n",
    "\n",
    "* 더 빠른 속도\n",
    "  * bagging_fraction\n",
    "  * max_bin은 작게\n",
    "  * save_binary를 쓰면 데이터 로딩속도가 빨라짐\n",
    "  * parallel learning 사용\n",
    "* 더 높은 정확도\n",
    "  * max_bin을 크게\n",
    "  * num_iterations 는 크게하고 learning_rate는 작게\n",
    "  * num_leaves를 크게(과적합의 원인이 될 수 있음)\n",
    "  * boosting 알고리즘 'dart' 사용\n",
    "* 과적합을 줄이기\n",
    "  * max_bin을 작게\n",
    "  * num_leaves를 작게\n",
    "  * min_data_in_leaf와 min_sum_hessian_in_leaf 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = LGBMClassifier(n_estimators=200)\n",
    "\n",
    "params = {'max_depth': [10, 15, 20],\n",
    "          'min_child_samples': [20, 40, 60],\n",
    "          'subsample': [0.8, 1]}\n",
    "\n",
    "grid = GridSearchCV(lgbm, param_grid=params)\n",
    "grid.fit(X_train, Y_train, early_stopping_rounds=100, eval_metric='auc',\n",
    "         eval_set=[(X_train, Y_train), (X_val, Y_val)])\n",
    "\n",
    "print(\"최적 파라미터: \", grid.best_params_)\n",
    "lgbm_roc_score = roc_auc_score(Y_test, grid.predict_proba(X_test)[:, 1], average='macro')\n",
    "print(\"ROC AUC: {0:.4f}\".format(lgbm_roc_score))\n",
    "\n",
    "# 위 결과를 적용하여 재학습\n",
    "lgbm = LGBMClassifier(n_estimators=1000, num_leaves=50, subsample=0.8,\n",
    "                      min_child_samples=60, max_depth=20)\n",
    "\n",
    "evals = [(X_test, Y_test)]\n",
    "lgbm.fit(X_train, Y_train, early_stopping_rounds=100, eval_metric='auc',\n",
    "         eval_set=evals, verbose=True)\n",
    "\n",
    "score = roc_auc_score(Y_test, grid.predict_proba(X_test)[:, 1], average='macro')\n",
    "print(\"ROC AUC: {0:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 평가지표\n",
    "\n",
    "1. 정확도 (Accuracy)\n",
    "   * 전체 예측 한 것중 맞게 예측한 비율로 평가한다.\n",
    "   * accuracy_score(모델예측값, 정답)\n",
    "   * 불균형 데이터의 경우 정확한 평가지표가 될 수 없다.\n",
    "     * 예: 양성과 음성의 비율이 1:9 인 경우 모두 음성이라고 하면 정확도는 90%가 된다.\n",
    "   \n",
    "2. 정밀도 (Precision)\n",
    "\n",
    "   * 실제 Positive(양성)인 것 중에 Positive(양성)로 예측 한 것의 비율\n",
    "   * TPR(True Positive Rate) 이라고도 한다.\n",
    "   * ex) 스팸 메일 중 스팸메일로 예측한 비율. 금융사기 데이터 중 사기로 예측한 비율\n",
    "   \n",
    "3. 재현률 (Recall)\n",
    "\n",
    "  * Positive(양성)으로 예측 한 것 중 실제 Positive(양성)인 비율\n",
    "  * PPV(Positive Predictive Value) 라고도 한다.\n",
    "  * ex) 스팸메일로 예측한 것 중 스팸메일의 비율. 금융 사기로 예측한 것 중 금융사기인 것의 비율\n",
    "   \n",
    "4. F1점수 (F1 Score)\n",
    "   * 정밀도와 재현율의 조화평균 점수\n",
    "  \n",
    "5. AUC\n",
    "   * FPR을 X축, TPR을 Y축으로 놓고 임계값을 변경해서 FPR이 변할 때 TPR이 어떻게 변하는지 나타내는 곡선.\n",
    "   * ROC 곡선 아래쪽 면적\n",
    "   * 0 ~ 1 사이 실수로 나오며 클수록 좋다.\n",
    "   * AUC 점수기준\n",
    "     * 1.0 ~ 0.9 : 아주 좋음\n",
    "     * 0.9 ~ 0.8 : 좋음\n",
    "     * 0.8 ~ 0.7 : 괜찮은 모델\n",
    "     * 0.7 ~ 0.6 : 의미는 있으나 좋은 모델은 아님\n",
    "     * 0.6 ~ 0.5 : 좋지 않은 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 재현율이 더 중요한 경우\n",
    "  * 실제 Positive 데이터를 Negative 로 잘못 판단하면 업무상 큰 영향이 있는 경우.\n",
    "  * FN(False Negative)를 낮추는데 촛점을 맞춘다.\n",
    "  * 암환자 판정 모델, 보험사기적발 모델\n",
    "* 정밀도가 더 중요한 경우\n",
    "  * 실제 Negative 데이터를 Positive 로 잘못 판단하면 업무상 큰 영향이 있는 경우.\n",
    "  * FP(False Positive)를 낮추는데 초점을 맞춘다.\n",
    "  * 스팸메일 판정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](confusion%20matrix1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report, roc_curve, roc_auc_score\n",
    "y_test = [1,2,3,4]\n",
    "y_pred = [2,3,2,1]\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "recall_score(y_test, y_pred)\n",
    "\n",
    "precision_score(y_test, y_pred)\n",
    "\n",
    "f1_score(y_test, y_pred)\n",
    "\n",
    "classification_report(y_test, y_pred)\n",
    "#클래스 별로 recall, precision, f1 점수와 accuracy를 종합해서 보여준다.\n",
    "\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fprs1, tprs1, thresholds1 = roc_curve(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(fprs1, tprs1, label='Tree-Roc곡선')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "roc_auc_score(y_test, y_pred) # auc score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold 교차검증\n",
    "\n",
    "https://ysyblog.tistory.com/69?category=1144778"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "acc_train_list = [] # 평가지표들을 저장할 리스트\n",
    "acc_test_list = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    # index를 이용해 훈련/검증 데이터셋 추출\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "\n",
    "    # 모델생성\n",
    "    tree = DecisionTreeClassifier()\n",
    "    # 학습\n",
    "    tree.fit(X_train, y_train)\n",
    "    # 검증\n",
    "    pred_train = tree.predict(X_train)\n",
    "    pred_test = tree.predict(X_test)\n",
    "\n",
    "    acc_train = accuracy_score(y_train, pred_train)\n",
    "    acc_test = accuracy_score(y_test, pred_test)\n",
    "    acc_train_list.append(acc_train)\n",
    "    acc_test_list.append(acc_test)\n",
    "\n",
    "acc_test_list, np.mean(acc_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 원 데이터셋의 row 순서대로 분할하기 때문에 불균형 문제가 발생할 수 있다.\n",
    "\n",
    "### Stratified KFold\n",
    "\n",
    "* 나뉜 fold 들에 label들이 같은(또는 거의 같은) 비율로 구성 되도록 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "s_fold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "for train_index, test_index in s_fold.split(X, y):\n",
    "\n",
    "# 다음부터는 위의 Kfold와 같이 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "\n",
    "* Kfold와 차이점은 그냥 점수만 계산해준다는 것인듯..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "score_list = cross_val_score(tree, X, y, scoring='accuracy', cv=3)\n",
    "\n",
    "score_list\n",
    "#==> array([0.98, 0.94, 0.98])\n",
    "np.mean(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 튜닝\n",
    "\n",
    "#### 그리드 서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "param_grid = {\n",
    "    'max_depth':[4,5,6,7],\n",
    "    'max_leaf_nodes':[3,5,7,9,10],\n",
    "    'criterion':['entropy'] #기본값 말고 다른값을 사용할 경우.\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(dt, \n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv = 3,\n",
    "                  n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "gs.best_parrams_ # 가장 좋은 성능을 보여준 파라미터\n",
    "gs.best_estimator_ # 가장 좋은 성능을 보인 모델\n",
    "gs.best_score_ # 가장 좋은 점수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 랜덤 서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "param = {\n",
    "    'max_depth':range(1, 21),\n",
    "    'max_leaf_nodes':range(5, 101, 5),\n",
    "    'criterion':['entropy','gini']\n",
    "}\n",
    "# 800\n",
    "n_iter = 80 #기본 :10\n",
    "\n",
    "rs = RandomizedSearchCV(dt,\n",
    "                        param_distributions=param,\n",
    "                        n_iter=n_iter, \n",
    "                        cv=5, \n",
    "                        n_jobs=-1)\n",
    "\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 앙상블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Voting의 유형**\n",
    "* hard voting\n",
    "  * 다수의 추정기가 결정한 예측값들 중 많은 것을 선택하는 방식\n",
    "\n",
    "* soft voting\n",
    "  * 다수의 추정기에서 각 레이블별 예측한 확률들의 평균을 내서 높은 레이블값을 결과값으로 선택하는 방식\n",
    "  * 일반적으로 soft voting이 성능이 더 좋다.\n",
    "  * Voting은 성향이 다르면서 비슷한 성능을 가진 모델들을 묶었을때 가장 좋은 성능을 낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "svm = SVC(C=0.1, gamma='auto', probability=True) #SVC 모델을 soft voting에 사용하려면 probability=True 로 설정해야 한다.\n",
    "lg = LogisticRegression()\n",
    "\n",
    "estimators = [('knn',knn), ('dt',dt), ('svm',svm), ('lg', lg)]\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "v_clf = VotingClassifier(estimators) #voting=\"hard\"-기본값 || voting=\"soft\"\n",
    "\n",
    "v_clf.fit(X_train, y_train) #각각의 모델을 학습\n",
    "\n",
    "pred_test = v_clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search를 이용한 Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "dt = DecisionTreeClassifier()\n",
    "gs_dt = GridSearchCV(dt, param_grid= {'max_depth':range(1,10)}, cv=5, n_jobs=-1)\n",
    "\n",
    "svm = SVC(probability=True)\n",
    "gs_svm = GridSearchCV(svm, param_grid={'C':[0.01,0.1,0.5,1], 'gamma':[0.01,0.1,0.5,1,5]}, cv=5, n_jobs=-1)\n",
    "\n",
    "estimators2 = [('gs_dt', gs_dt), ('gs_svm', gs_svm)]\n",
    "\n",
    "v_clf2 = VotingClassifier(estimators2, voting='soft')\n",
    "\n",
    "v_clf2.fit(X_train, y_train)\n",
    "\n",
    "pred_test = v_clf2.predict(X_test)\n",
    "\n",
    "accuracy_score(y_train, pred_train), accuracy_score(y_test, pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('adp': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e121dbc38053d2982f45d1933ef59f2d15b105186547436b8f27260be9038f3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
